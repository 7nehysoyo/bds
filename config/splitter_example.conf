#占用cup核心数
[global]
max_process = 1

#堆栈监控
[profiling]
enable = true
host = 0.0.0.0
port = 6062

#内部数据监控
[metric]
enable = false
host = 0.0.0.0
port = 6063
path = /metrics

# =============================== btc ==================================
[btc]
#是否开启 btc 数据splitter
enable = true
#是否开启数据库
database_enable = true
#数据库worker缓存大小
database_worker_buffer = 8192
#数据库worker数量
database_worker_number = 1
#一次请求区块链数据的最大块数,400000块之前可以设置大一些，比如300
max_batch_block = 30
#btc全节点的地址 
endpoint = http://[btc 全节点的ip/域名]:[btc 全节点运行端口]
#运行 btc 全节点设置的用户名
user = [rpc 访问账号]
#运行 btc 全节点设置的密码
password = [rpc 访问密码]
#btc数据校验规则文件地址
json_schema_file = /etc/bds-splitter/schema/btc.json↩
#btc数据校验是否开启
json_schema_validation_enable = false

#btc定时任务配置
[cron.btc]
update_meta_expr = @every 1m

#btc kafka 配置
[kafka.btc]
enable = true
topic = btc
# kafka 客户端标示
client_id = btc-client-1
# kafka 消费组标示
group_id = btc-group
# kafka 服务的地址
broker_list = [kafka 服务的ip/域名]:[kafka 服务的运行端口] 
buffer_size = 1000
return_errors = true

#btc数据库配置
[database.btc]
#数据库类型，sql server为mssql，postgre为postgres
type = postgres 
#数据库的访问地址
host = [数据库服务的ip/域名] 
#数据库的端口信息
port = [数据库服务的端口] 
#数据库的库名，需要初始化好，创建表和导入数据用
database = [数据库服务的库] 
#数据库的访问账号
user = [数据库服务的账号] 
#数据库的访问账号密码信息
password = [数据库服务的密码]
timezone = Asia/Shanghai
max_open_conns = 500
max_idle_conns = 100
sql_log_file = /var/log/bds-splitter/btc-sql.log
debug = false

# =============================== bch ==================================
[bch]
#是否开启 bch 数据splitter
enable = true
#是否开启数据库
database_enable = true
#数据库worker缓存大小
database_worker_buffer = 8192
#数据库worker数量
database_worker_number = 1
#一次请求区块链数据的最大块数,400000块之前可以设置大一些，比如300
max_batch_block = 30
#bch 全节点的地址
endpoint = http://[bch 全节点的ip/域名]:[bch 全节点运行端口]
#运行 bch 全节点设置的用户名
user = [rpc 访问账号]
#运行 bch 全节点设置的密码
password = [rpc 访问密码]
#bch 数据校验规则文件地址
json_schema_file = /etc/bds-splitter/schema/bch.json↩
#bch 数据校验是否开启
json_schema_validation_enable = false

#bch 定时任务配置
[cron.bch]
update_meta_expr = @every 1m

#bch kafka 配置
[kafka.bch]
enable = true
topic = bch
# kafka 客户端标示
client_id = bch-client-1
# kafka 消费组标示
group_id = bch-group
# kafka 服务的地址
broker_list = [kafka 服务的ip/域名]:[kafka 服务的运行端口]
buffer_size = 1000
return_errors = true

#bch 数据库配置
[database.bch]
#数据库类型，sql server为mssql，postgre为postgres
type = postgres 
#数据库的访问地址
host = [数据库服务的ip/域名]
#数据库的端口信息
port = [数据库服务的端口]
#数据库的库名，需要初始化好，创建表和导入数据用
database = [数据库服务的库]
#数据库的访问账号
user = [数据库服务的账号]
#数据库的访问账号密码信息
password = [数据库服务的密码]
timezone = Asia/Shanghai
max_open_conns = 500
max_idle_conns = 100
sql_log_file = /var/log/bds-splitter/bch-sql.log
debug = false

# =============================== bsv ==================================
[bsv]
#是否开启 bsv 数据splitter
enable = true
#是否开启数据库
database_enable = true
#数据库worker缓存大小
database_worker_buffer = 8192
#数据库worker数量
database_worker_number = 1
#一次请求区块链数据的最大块数,400000块之前可以设置大一些，比如300
max_batch_block = 30
#bsv 全节点的地址
endpoint = http://[bsv 全节点的ip/域名]:[bsv 全节点运行端口]
#运行 bsv 全节点设置的用户名
user = [rpc 访问账号]
#运行 bsv 全节点设置的密码
password = [rpc 访问密码]
#bsv 数据校验规则文件地址
json_schema_file = /etc/bds-splitter/schema/bsv.json↩
#bsv 数据校验是否开启
json_schema_validation_enable = false

#bsv 定时任务配置
[cron.bsv]
update_meta_expr = @every 1m

#bsv kafka 配置
[kafka.bsv]
enable = true
topic = bch
# kafka 客户端标示
client_id = bsv-client-1
# kafka 消费组标示
group_id = bsvn-group
# kafka 服务的地址
broker_list = [kafka 服务的ip/域名]:[kafka 服务的运行端口]
buffer_size = 1000
return_errors = true

#bsv 数据库配置
[database.bsv]
#数据库类型，sql server为mssql，postgre为postgres
type = postgres
#数据库的访问地址
host = [数据库服务的ip/域名]
#数据库的端口信息
port = [数据库服务的端口]
#数据库的库名，需要初始化好，创建表和导入数据用
database = [数据库服务的库]
#数据库的访问账号
user = [数据库服务的账号]
#数据库的访问账号密码信息
password = [数据库服务的密码]
timezone = Asia/Shanghai
max_open_conns = 500
max_idle_conns = 100
sql_log_file = /var/log/bds-splitter/bsv-sql.log
debug = false

# =============================== ltc ==================================
[ltc]
#是否开启 ltc 数据splitter
enable = true
#是否开启数据库
database_enable = true
#数据库worker缓存大小
database_worker_buffer = 8192
#数据库worker数量
database_worker_number = 1
#一次请求区块链数据的最大块数,400000块之前可以设置大一些，比如300
max_batch_block = 30
#ltc 全节点的地址
endpoint = http://[ltc 全节点的ip/域名]:[ltc 全节点运行端口]
#运行 ltc 全节点设置的用户名
user = [rpc 访问账号]
#运行 ltc 全节点设置的密码
password = [rpc 访问密码]
#ltc 数据校验规则文件地址
json_schema_file = /etc/bds-splitter/schema/ltc.json↩
#ltc 数据校验是否开启
json_schema_validation_enable = false

#ltc 定时任务配置
[cron.ltc]
update_meta_expr = @every 1m

#ltc kafka 配置
[kafka.ltc]
enable = true
topic = ltc
# kafka 客户端标示
client_id = ltc-client-1
# kafka 消费组标示
group_id = ltcn-group
# kafka 服务的地址
broker_list = [kafka 服务的ip/域名]:[kafka 服务的运行端口]
buffer_size = 1000
return_errors = true

#ltc 数据库配置
[database.ltc]
#数据库类型，sql server为mssql，postgre为postgres
type = postgres
#数据库的访问地址
host = [数据库服务的ip/域名]
#数据库的端口信息
port = [数据库服务的端口]
#数据库的库名，需要初始化好，创建表和导入数据用
database = [数据库服务的库]
#数据库的访问账号
user = [数据库服务的账号]
#数据库的访问账号密码信息
password = [数据库服务的密码]
timezone = Asia/Shanghai
max_open_conns = 500
max_idle_conns = 100
sql_log_file = /var/log/bds-splitter/ltc-sql.log
debug = false

# =============================== log ==================================
#普通日志配置
[logging_normal]
writers = console,file
log_file = /var/log/bds-splitter/normal.log
log_level = debug
caller_level_skip = 5
format = short
max_size = 100m
daily = true

#错误日志配置
[logging_detail]
writers = console,file
log_file = /var/log/bds-splitter/detail.log
log_level = debug
caller_level_skip = 5
format = long
max_size = 100m
daily = true
