#占用cup核心数
[global]
max_process = 1

#堆栈监控
[profiling]
enable = true
host = 0.0.0.0
port = 6062

#内部数据监控
[metric]
enable = false
host = 0.0.0.0
port = 6063
path = /metrics

# =============================== btc ==================================
[btc]
#是否开启 btc 数据splitter
enable = true
#是否开启数据库
database_enable = true
#数据库worker缓存大小
database_worker_buffer = 8192
#数据库worker数量
database_worker_number = 1
#一次请求区块链数据的最大块数,400000块之前可以设置大一些，比如300
max_batch_block = 30
#btc全节点的地址 
endpoint = http://[btc 全节点的ip/域名]:[btc 全节点运行端口]
#运行 btc 全节点设置的用户名
user = [rpc 访问账号]
#运行 btc 全节点设置的密码
password = [rpc 访问密码]
#btc数据校验规则文件地址
json_schema_file = /etc/bds-splitter/schema/btc.json↩
#btc数据校验是否开启
json_schema_validation_enable = false

#btc定时任务配置
[cron.btc]
update_meta_expr = @every 1m

#btc kafka 配置
[kafka.btc]
enable = true
topic = btc
# kafka 客户端标示
client_id = btc-client-1
# kafka 消费组标示
group_id = btc-group
# kafka 服务的地址
broker_list = [kafka 服务的ip/域名]:[kafka 服务的运行端口] 
buffer_size = 1000
return_errors = true

#btc数据库配置
[database.btc]
#数据库类型，sql server为mssql，postgre为postgres
type = postgres 
#数据库的访问地址
host = [数据库服务的ip/域名] 
#数据库的端口信息
port = [数据库服务的端口] 
#数据库的库名，需要初始化好，创建表和导入数据用
database = [数据库服务的库] 
#数据库的访问账号
user = [数据库服务的账号] 
#数据库的访问账号密码信息
password = [数据库服务的密码]
timezone = Asia/Shanghai
max_open_conns = 500
max_idle_conns = 100
sql_log_file = /var/log/bds-splitter/btc-sql.log
debug = false

# =============================== bch ==================================
[bch]
#是否开启 bch 数据splitter
enable = true
#是否开启数据库
database_enable = true
#数据库worker缓存大小
database_worker_buffer = 8192
#数据库worker数量
database_worker_number = 1
#一次请求区块链数据的最大块数,400000块之前可以设置大一些，比如300
max_batch_block = 30
#bch 全节点的地址
endpoint = http://[bch 全节点的ip/域名]:[bch 全节点运行端口]
#运行 bch 全节点设置的用户名
user = [rpc 访问账号]
#运行 bch 全节点设置的密码
password = [rpc 访问密码]
#bch 数据校验规则文件地址
json_schema_file = /etc/bds-splitter/schema/bch.json↩
#bch 数据校验是否开启
json_schema_validation_enable = false

#bch 定时任务配置
[cron.bch]
update_meta_expr = @every 1m

#bch kafka 配置
[kafka.bch]
enable = true
topic = bch
# kafka 客户端标示
client_id = bch-client-1
# kafka 消费组标示
group_id = bch-group
# kafka 服务的地址
broker_list = [kafka 服务的ip/域名]:[kafka 服务的运行端口]
buffer_size = 1000
return_errors = true

#bch 数据库配置
[database.bch]
#数据库类型，sql server为mssql，postgre为postgres
type = postgres 
#数据库的访问地址
host = [数据库服务的ip/域名]
#数据库的端口信息
port = [数据库服务的端口]
#数据库的库名，需要初始化好，创建表和导入数据用
database = [数据库服务的库]
#数据库的访问账号
user = [数据库服务的账号]
#数据库的访问账号密码信息
password = [数据库服务的密码]
timezone = Asia/Shanghai
max_open_conns = 500
max_idle_conns = 100
sql_log_file = /var/log/bds-splitter/bch-sql.log
debug = false

# =============================== bsv ==================================
[bsv]
#是否开启 bsv 数据splitter
enable = true
#是否开启数据库
database_enable = true
#数据库worker缓存大小
database_worker_buffer = 8192
#数据库worker数量
database_worker_number = 1
#一次请求区块链数据的最大块数,400000块之前可以设置大一些，比如300
max_batch_block = 30
#bsv 全节点的地址
endpoint = http://[bsv 全节点的ip/域名]:[bsv 全节点运行端口]
#运行 bsv 全节点设置的用户名
user = [rpc 访问账号]
#运行 bsv 全节点设置的密码
password = [rpc 访问密码]
#bsv 数据校验规则文件地址
json_schema_file = /etc/bds-splitter/schema/bsv.json↩
#bsv 数据校验是否开启
json_schema_validation_enable = false

#bsv 定时任务配置
[cron.bsv]
update_meta_expr = @every 1m

#bsv kafka 配置
[kafka.bsv]
enable = true
topic = bch
# kafka 客户端标示
client_id = bsv-client-1
# kafka 消费组标示
group_id = bsvn-group
# kafka 服务的地址
broker_list = [kafka 服务的ip/域名]:[kafka 服务的运行端口]
buffer_size = 1000
return_errors = true

#bsv 数据库配置
[database.bsv]
#数据库类型，sql server为mssql，postgre为postgres
type = postgres
#数据库的访问地址
host = [数据库服务的ip/域名]
#数据库的端口信息
port = [数据库服务的端口]
#数据库的库名，需要初始化好，创建表和导入数据用
database = [数据库服务的库]
#数据库的访问账号
user = [数据库服务的账号]
#数据库的访问账号密码信息
password = [数据库服务的密码]
timezone = Asia/Shanghai
max_open_conns = 500
max_idle_conns = 100
sql_log_file = /var/log/bds-splitter/bsv-sql.log
debug = false

# =============================== ltc ==================================
[ltc]
#是否开启 ltc 数据splitter
enable = true
#是否开启数据库
database_enable = true
#数据库worker缓存大小
database_worker_buffer = 8192
#数据库worker数量
database_worker_number = 1
#一次请求区块链数据的最大块数,400000块之前可以设置大一些，比如300
max_batch_block = 30
#ltc 全节点的地址
endpoint = http://[ltc 全节点的ip/域名]:[ltc 全节点运行端口]
#运行 ltc 全节点设置的用户名
user = [rpc 访问账号]
#运行 ltc 全节点设置的密码
password = [rpc 访问密码]
#ltc 数据校验规则文件地址
json_schema_file = /etc/bds-splitter/schema/ltc.json↩
#ltc 数据校验是否开启
json_schema_validation_enable = false

#ltc 定时任务配置
[cron.ltc]
update_meta_expr = @every 1m

#ltc kafka 配置
[kafka.ltc]
enable = true
topic = ltc
# kafka 客户端标示
client_id = ltc-client-1
# kafka 消费组标示
group_id = ltcn-group
# kafka 服务的地址
broker_list = [kafka 服务的ip/域名]:[kafka 服务的运行端口]
buffer_size = 1000
return_errors = true

#ltc 数据库配置
[database.ltc]
#数据库类型，sql server为mssql，postgre为postgres
type = postgres
#数据库的访问地址
host = [数据库服务的ip/域名]
#数据库的端口信息
port = [数据库服务的端口]
#数据库的库名，需要初始化好，创建表和导入数据用
database = [数据库服务的库]
#数据库的访问账号
user = [数据库服务的账号]
#数据库的访问账号密码信息
password = [数据库服务的密码]
timezone = Asia/Shanghai
max_open_conns = 500
max_idle_conns = 100
sql_log_file = /var/log/bds-splitter/ltc-sql.log
debug = false

# =============================== eth ==================================
[eth]
#是否开启 eth 数据splitter
enable = true
#是否开启数据库
database_enable = true
#数据库worker缓存大小
database_worker_buffer = 8192
#数据库worker数量
database_worker_number = 1
#一次请求区块链数据的最大块数,400000块之前可以设置大一些，比如300
max_batch_block = 30
#eth 全节点的地址
endpoint = http://[eth 全节点的ip/域名]:[eth 全节点运行端口]
#运行 eth 全节点设置的用户名
user = [rpc 访问账号]
#运行 eth 全节点设置的密码
password = [rpc 访问密码]
#eth 数据校验规则文件地址
json_schema_file = /etc/bds-splitter/schema/eth.json↩
#eth 数据校验是否开启
json_schema_validation_enable = false

#eth 定时任务配置
[cron.eth]
update_meta_expr = @every 1m

#eth kafka 配置
[kafka.eth]
enable = true
topic = eth
# kafka 客户端标示
client_id = eth-client-1
# kafka 消费组标示
group_id = eth-group
# kafka 服务的地址
broker_list = [kafka 服务的ip/域名]:[kafka 服务的运行端口]
buffer_size = 1000
return_errors = true

#eth 数据库配置
[database.eth]
#数据库类型，sql server为mssql，postgre为postgres
type = postgres
#数据库的访问地址
host = [数据库服务的ip/域名]
#数据库的端口信息
port = [数据库服务的端口]
#数据库的库名，需要初始化好，创建表和导入数据用
database = [数据库服务的库]
#数据库的访问账号
user = [数据库服务的账号]
#数据库的访问账号密码信息
password = [数据库服务的密码]
timezone = Asia/Shanghai
max_open_conns = 500
max_idle_conns = 100
sql_log_file = /var/log/bds-splitter/eth-sql.log
debug = false

# =============================== tron ==================================
[tron]
#是否开启 tron 数据splitter
enable = true
#是否开启数据库
database_enable = true
#数据库worker缓存大小
database_worker_buffer = 8192
#数据库worker数量
database_worker_number = 1
#并发落库的区块高度
concurrent_height = 12000000
#一次请求区块链数据的最大块数,400000块之前可以设置大一些，比如300
max_batch_block = 1000
skip_miss_block = false
skip_height = 0
#tron 全节点的地址
endpoint = http://[tron 全节点的ip/域名]:[tron 全节点运行端口]
#运行 tron 全节点设置的用户名
user = [rpc 访问账号]
#运行 tron 全节点设置的密码
password = [rpc 访问密码]
#tron 数据校验规则文件地址
json_schema_file = /etc/bds-splitter/schema/tron.json↩
#tron 数据校验是否开启
json_schema_validation_enable = false

#tron 定时任务配置
[cron.tron]
update_meta_expr = @every 1m

#tron kafka 配置
[kafka.tron]
enable = true
topic = trx
# kafka 客户端标示
client_id = tron-client-1
# kafka 消费组标示
group_id = tron-group
# kafka 服务的地址
broker_list = [kafka 服务的ip/域名]:[kafka 服务的运行端口]
buffer_size = 1000
return_errors = true

#tron 数据库配置
[database.tron]
#数据库类型，sql server为mssql，postgre为postgres
type = postgres
#数据库的访问地址
host = [数据库服务的ip/域名]
#数据库的端口信息
port = [数据库服务的端口]
#数据库的库名，需要初始化好，创建表和导入数据用
database = [数据库服务的库]
#数据库的访问账号
user = [数据库服务的账号]
#数据库的访问账号密码信息
password = [数据库服务的密码]
timezone = Asia/Shanghai
max_open_conns = 500
max_idle_conns = 100
sql_log_file = /var/log/bds-splitter/tron-sql.log
debug = false

# =============================== doge ==================================
[doge]
#是否开启 doge 数据splitter
enable = true
#是否开启数据库
database_enable = true
#数据库worker缓存大小
database_worker_buffer = 8192
#数据库worker数量
database_worker_number = 1
#一次请求区块链数据的最大块数,400000块之前可以设置大一些，比如300
max_batch_block = 30
#doge全节点的地址
endpoint = http://[doge 全节点的ip/域名]:[doge 全节点运行端口]
#运行 doge 全节点设置的用户名
user = [rpc 访问账号]
#运行 doge 全节点设置的密码
password = [rpc 访问密码]
#doge数据校验规则文件地址
json_schema_file = /etc/bds-splitter/schema/doge.json↩
#doge数据校验是否开启
json_schema_validation_enable = false

#doge定时任务配置
[cron.doge]
update_meta_expr = @every 1m

#doge kafka 配置
[kafka.doge]
enable = true
topic = doge
# kafka 客户端标示
client_id = doge-client-1
# kafka 消费组标示
group_id = doge-group
# kafka 服务的地址
broker_list = [kafka 服务的ip/域名]:[kafka 服务的运行端口]
buffer_size = 1000
return_errors = true

#doge数据库配置
[database.doge]
#数据库类型，sql server为mssql，postgre为postgres
type = postgres
#数据库的访问地址
host = [数据库服务的ip/域名]
#数据库的端口信息
port = [数据库服务的端口]
#数据库的库名，需要初始化好，创建表和导入数据用
database = [数据库服务的库]
#数据库的访问账号
user = [数据库服务的账号]
#数据库的访问账号密码信息
password = [数据库服务的密码]
timezone = Asia/Shanghai
max_open_conns = 500
max_idle_conns = 100
sql_log_file = /var/log/bds-splitter/doge-sql.log
debug = false

# =============================== etc ==================================
[etc]
#是否开启 etc 数据splitter
enable = true
#是否开启数据库
database_enable = true
#数据库worker缓存大小
database_worker_buffer = 8192
#数据库worker数量
database_worker_number = 1
#一次请求区块链数据的最大块数,400000块之前可以设置大一些，比如300
max_batch_block = 100
#etc 全节点的地址
endpoint = http://[etc 全节点的ip/域名]:[etc 全节点运行端口]
#etc 数据校验规则文件地址
json_schema_file = /etc/bds-splitter/schema/etc.json↩
#etc 数据校验是否开启
json_schema_validation_enable = false

#etc 定时任务配置
[cron.etc]
update_meta_expr = @every 1m

#etc kafka 配置
[kafka.etc]
enable = true
topic = etc
# kafka 客户端标示
client_id = etc-client-1
# kafka 消费组标示
group_id = etc-group
# kafka 服务的地址
broker_list = [kafka 服务的ip/域名]:[kafka 服务的运行端口]
buffer_size = 1000
return_errors = true

#etc 数据库配置
[database.etc]
#数据库类型，sql server为mssql，postgre为postgres
type = postgres
#数据库的访问地址
host = [数据库服务的ip/域名]
#数据库的端口信息
port = [数据库服务的端口]
#数据库的库名，需要初始化好，创建表和导入数据用
database = [数据库服务的库]
#数据库的访问账号
user = [数据库服务的账号]
#数据库的访问账号密码信息
password = [数据库服务的密码]
timezone = Asia/Shanghai
max_open_conns = 500
max_idle_conns = 100
sql_log_file = /var/log/bds-splitter/etc-sql.log
debug = false

# =============================== xlm ==================================
[xlm]
#是否开启 exlm 数据splitter
enable = true
#是否开启数据库
database_enable = true
#数据库worker缓存大小
database_worker_buffer = 8192
#数据库worker数量
database_worker_number = 20
skip_height = 0
skip_miss_block = false
#一次请求区块链数据的最大块数,400000块之前可以设置大一些，比如300
max_batch_block = 1000
#xlm 全节点的地址
endpoint = http://[xlm 全节点的ip/域名]:[xlm 全节点运行端口]
#xlm 数据校验规则文件地址
json_schema_file = /etc/bds-splitter/schema/xlm.json↩
#etc 数据校验是否开启
json_schema_validation_enable = false
concurrent_height = 22822347
concurrent_http = 5

#xlm 定时任务配置
[cron.xlm]
update_meta_expr = @every 1m

#xlm kafka 配置
[kafka.xlm]
enable = true
topic = xlm
# kafka 客户端标示
client_id = xlm-client-1
# kafka 消费组标示
group_id = xlm-group
# kafka 服务的地址
broker_list = [kafka 服务的ip/域名]:[kafka 服务的运行端口]
buffer_size = 1000
return_errors = true

#xlm 数据库配置
[database.xlm]
#数据库类型，sql server为mssql，postgre为postgres
type = postgres
#数据库的访问地址
host = [数据库服务的ip/域名]
#数据库的端口信息
port = [数据库服务的端口]
#数据库的库名，需要初始化好，创建表和导入数据用
database = [数据库服务的库]
#数据库的访问账号
user = [数据库服务的账号]
#数据库的访问账号密码信息
password = [数据库服务的密码]
timezone = Asia/Shanghai
max_open_conns = 500
max_idle_conns = 100
sql_log_file = /var/log/bds-splitter/xlm-sql.log
debug = false


# =============================== log ==================================
#普通日志配置
[logging_normal]
writers = console,file
log_file = /var/log/bds-splitter/normal.log
log_level = debug
caller_level_skip = 5
format = short
max_size = 100m
daily = true

#错误日志配置
[logging_detail]
writers = console,file
log_file = /var/log/bds-splitter/detail.log
log_level = debug
caller_level_skip = 5
format = long
max_size = 100m
daily = true
